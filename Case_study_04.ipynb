{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IENRM1GTBciy",
        "outputId": "d1783306-d0c8-4582-d4e5-12025e77d54f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Train data"
      ],
      "metadata": {
        "id": "wSws3cnaMNMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2,os\n",
        "\n",
        "data_path = '/content/drive/MyDrive/Vegetable Images/train'\n",
        "categories =os .listdir(data_path)\n",
        "labels = [i for i in range(len(categories))]\n",
        "\n",
        "label_dict = dict(zip(categories,labels))\n",
        "\n",
        "print(label_dict)\n",
        "print(categories)\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "7t5GxTaEBfp_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11943ff4-782b-499d-831c-6452e5eca665"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Bean': 0, 'Bitter_Gourd': 1, 'Bottle_Gourd': 2, 'Brinjal': 3, 'Broccoli': 4, 'Cabbage': 5, 'Capsicum': 6, 'Carrot': 7, 'Cauliflower': 8, 'Cucumber': 9, 'Papaya': 10, 'Potato': 11, 'Pumpkin': 12, 'Radish': 13, 'Tomato': 14}\n",
            "['Bean', 'Bitter_Gourd', 'Bottle_Gourd', 'Brinjal', 'Broccoli', 'Cabbage', 'Capsicum', 'Carrot', 'Cauliflower', 'Cucumber', 'Papaya', 'Potato', 'Pumpkin', 'Radish', 'Tomato']\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 100\n",
        "data = []\n",
        "target = []\n",
        "\n",
        "\n",
        "for category in categories:\n",
        "    folder_path = os.path.join(data_path,category)\n",
        "    img_names = os.listdir(folder_path)\n",
        "\n",
        "    for img_name in img_names:\n",
        "        img_path =os.path.join(folder_path,img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        try:\n",
        "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "            #Coverting the image into gray scale\n",
        "            resized = cv2.resize(gray,(img_size,img_size))\n",
        "            #resizing the gray scale into 100x100, since we need a fixed common size for all the images in the dataset\n",
        "            data.append(resized)\n",
        "            target.append(label_dict[category])\n",
        "            #appending the image and the label(categorized) into the list (dataset)\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception:',e)\n",
        "            #if any exception rasied, the exception will be printed here. And pass to the next image"
      ],
      "metadata": {
        "id": "hl0JoTk1ELdH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.array(data)/255.0\n",
        "data = np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
        "target = np.array(target)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "new_target = to_categorical(target)"
      ],
      "metadata": {
        "id": "pFalK1QkEXtD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('train_data',data)\n",
        "np.save('train_target',new_target)"
      ],
      "metadata": {
        "id": "VRS__O5FFgxN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing test data"
      ],
      "metadata": {
        "id": "Q7AE15y4FtpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/Vegetable Images/test'\n",
        "categories =os .listdir(data_path)\n",
        "labels = [i for i in range(len(categories))]\n",
        "\n",
        "label_dict = dict(zip(categories,labels))\n",
        "\n",
        "print(label_dict)\n",
        "print(categories)\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T0jC1G7FmFF",
        "outputId": "3b22f3fd-25fd-4caf-87ee-97c7e7bc7f76"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Bean': 0, 'Bitter_Gourd': 1, 'Bottle_Gourd': 2, 'Brinjal': 3, 'Broccoli': 4, 'Cabbage': 5, 'Capsicum': 6, 'Carrot': 7, 'Cauliflower': 8, 'Cucumber': 9, 'Papaya': 10, 'Potato': 11, 'Pumpkin': 12, 'Radish': 13, 'Tomato': 14}\n",
            "['Bean', 'Bitter_Gourd', 'Bottle_Gourd', 'Brinjal', 'Broccoli', 'Cabbage', 'Capsicum', 'Carrot', 'Cauliflower', 'Cucumber', 'Papaya', 'Potato', 'Pumpkin', 'Radish', 'Tomato']\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 100\n",
        "data = []\n",
        "target = []\n",
        "\n",
        "\n",
        "for category in categories:\n",
        "    folder_path = os.path.join(data_path,category)\n",
        "    img_names = os.listdir(folder_path)\n",
        "\n",
        "    for img_name in img_names:\n",
        "        img_path =os.path.join(folder_path,img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        try:\n",
        "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "            #Coverting the image into gray scale\n",
        "            resized = cv2.resize(gray,(img_size,img_size))\n",
        "            #resizing the gray scale into 100x100, since we need a fixed common size for all the images in the dataset\n",
        "            data.append(resized)\n",
        "            target.append(label_dict[category])\n",
        "            #appending the image and the label(categorized) into the list (dataset)\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception:',e)\n",
        "            #if any exception rasied, the exception will be printed here. And pass to the next image"
      ],
      "metadata": {
        "id": "zrJNq7ynFzSA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.array(data)/255.0\n",
        "data = np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
        "target = np.array(target)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "new_target = to_categorical(target)"
      ],
      "metadata": {
        "id": "evui8pcTF5D1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('test_data',data)\n",
        "np.save('test_target',new_target)"
      ],
      "metadata": {
        "id": "eaVqPl4EF-Rl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Validation data"
      ],
      "metadata": {
        "id": "nCmXSALrGLVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/Vegetable Images/validation (1)'\n",
        "categories =os .listdir(data_path)\n",
        "labels = [i for i in range(len(categories))]\n",
        "\n",
        "label_dict = dict(zip(categories,labels))\n",
        "\n",
        "print(label_dict)\n",
        "print(categories)\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtXhzaXfGAeg",
        "outputId": "2512349f-259e-42bd-bf36-e27fde55a690"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Bean': 0, 'Bitter_Gourd': 1, 'Bottle_Gourd': 2, 'Brinjal': 3, 'Broccoli': 4, 'Cabbage': 5, 'Capsicum': 6, 'Carrot': 7, 'Cauliflower': 8, 'Cucumber': 9, 'Papaya': 10, 'Potato': 11, 'Pumpkin': 12, 'Radish': 13, 'Tomato': 14}\n",
            "['Bean', 'Bitter_Gourd', 'Bottle_Gourd', 'Brinjal', 'Broccoli', 'Cabbage', 'Capsicum', 'Carrot', 'Cauliflower', 'Cucumber', 'Papaya', 'Potato', 'Pumpkin', 'Radish', 'Tomato']\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 100\n",
        "data = []\n",
        "target = []\n",
        "\n",
        "\n",
        "for category in categories:\n",
        "    folder_path = os.path.join(data_path,category)\n",
        "    img_names = os.listdir(folder_path)\n",
        "\n",
        "    for img_name in img_names:\n",
        "        img_path =os.path.join(folder_path,img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        try:\n",
        "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "            #Coverting the image into gray scale\n",
        "            resized = cv2.resize(gray,(img_size,img_size))\n",
        "            #resizing the gray scale into 100x100, since we need a fixed common size for all the images in the dataset\n",
        "            data.append(resized)\n",
        "            target.append(label_dict[category])\n",
        "            #appending the image and the label(categorized) into the list (dataset)\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception:',e)\n",
        "            #if any exception rasied, the exception will be printed here. And pass to the next image"
      ],
      "metadata": {
        "id": "vuCU9Mv2GThk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.array(data)/255.0\n",
        "data = np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
        "target = np.array(target)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "new_target = to_categorical(target)"
      ],
      "metadata": {
        "id": "wCD1RM7EGVwB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('validation_data',data)\n",
        "np.save('validation_target',new_target)"
      ],
      "metadata": {
        "id": "w2W6TY0eGXug"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "train_data = np.load('/content/train_data.npy')\n",
        "train_target = np.load('/content/train_target.npy')\n",
        "validation_data = np.load('/content/validation_data.npy')\n",
        "validation_target = np.load('/content/validation_target.npy')\n",
        "test_data = np.load('/content/test_data.npy')\n",
        "test_target = np.load('/content/test_target.npy')"
      ],
      "metadata": {
        "id": "uWAFeUbtOCQK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.regularizers import l2\n",
        "model = Sequential() # model object\n",
        "\n",
        "# Add Layers\n",
        "model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=[150, 150, 3]))\n",
        "model.add(MaxPooling2D(2, ))\n",
        "model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "# Flatten the feature map\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add the fully connected layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(15, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyG8lJYImskm",
        "outputId": "efb695ed-bde1-47a1-ee95-5a6e21f18c56"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 150, 150, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 75, 75, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 75, 75, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 37, 37, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 87616)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               11214976  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11252815 (42.93 MB)\n",
            "Trainable params: 11252815 (42.93 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uwg8sRFdeEwj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}